import pandas as pd
import os
import shutil
from typing import List, Dict
from fastapi import UploadFile
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.docstore.document import Document
import pathlib

# å®šä¹‰æ•°æ®è·¯å¾„ - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
BASE_DIR = pathlib.Path(__file__).parent.parent.parent.absolute() # æ”¹ä¸ºç›¸å¯¹è·¯å¾„
DATA_DIR = BASE_DIR / "data"
CSV_PATH = DATA_DIR / "faq.csv"
FAISS_PATH = DATA_DIR / "faq_faiss"

embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# === è½½å…¥æ•°æ® ===
def load_faq_docs(csv_path: str = CSV_PATH) -> List[Document]:
    df = pd.read_csv(csv_path)
    docs = []
    for _, row in df.iterrows():
        content = f"Q: {row['question']}\nA: {row['answer']}"
        docs.append(Document(page_content=content))
    return docs

# === ä¸Šä¼ CSVå¹¶æ›´æ–°å‘é‡æ•°æ®åº“ ===
async def upload_csv_and_update_db(file: UploadFile) -> Dict:
    """
    ä¸Šä¼ CSVæ–‡ä»¶å¹¶æ›´æ–°å‘é‡æ•°æ®åº“
    
    Args:
        file: ä¸Šä¼ çš„CSVæ–‡ä»¶
        
    Returns:
        åŒ…å«æ“ä½œç»“æœçš„å­—å…¸
    """
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    os.makedirs(DATA_DIR, exist_ok=True)
    
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    temp_file_path = f"{DATA_DIR}/temp_{file.filename}"
    
    try:
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with open(temp_file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # éªŒè¯CSVæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆè‡³å°‘åŒ…å«questionå’Œansweråˆ—ï¼‰
        try:
            df = pd.read_csv(temp_file_path)
            if "question" not in df.columns or "answer" not in df.columns:
                os.remove(temp_file_path)
                return {"success": False, "message": "CSVæ–‡ä»¶å¿…é¡»åŒ…å«'question'å’Œ'answer'åˆ—"}
            if df.empty:
                return {"success": False, "message": "CSVæ–‡ä»¶ä¸åŒ…å«ä»»ä½•æ•°æ®"}
        except Exception as e:
            os.remove(temp_file_path)
            return {"success": False, "message": f"CSVæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}"}
        
        # å¤‡ä»½åŸå§‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(CSV_PATH):
            backup_path = f"{CSV_PATH}.bak"
            shutil.copy2(CSV_PATH, backup_path)
        
        # æ›¿æ¢åŸå§‹æ–‡ä»¶
        shutil.move(temp_file_path, CSV_PATH)
        
        # åˆ é™¤æ—§çš„å‘é‡æ•°æ®åº“
        if os.path.exists(FAISS_PATH):
            shutil.rmtree(FAISS_PATH)
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(FAISS_PATH, exist_ok=True)
        
        # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“
        faq_docs = load_faq_docs(str(CSV_PATH))
        
        # ä½¿ç”¨é‡å»ºå‡½æ•°æ¥æ›´æ–°å‘é‡æ•°æ®åº“ï¼Œå¹¶ç¡®ä¿æ›´æ–°å…¨å±€å˜é‡
        global vectorstore, retriever
        vectorstore, retriever = rebuild_vectorstore()
        
        return {
            "success": True, 
            "message": "CSVæ–‡ä»¶ä¸Šä¼ æˆåŠŸå¹¶æ›´æ–°äº†å‘é‡æ•°æ®åº“", 
            "document_count": len(faq_docs)
        }
    
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        print(f"âŒ å¤„ç†CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return {"success": False, "message": f"å¤„ç†CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

# === åˆ é™¤CSVæ–‡ä»¶ ===
def delete_csv() -> Dict:
    """
    åˆ é™¤CSVæ–‡ä»¶å¹¶æ¸…ç†å‘é‡æ•°æ®åº“
    
    Returns:
        åŒ…å«æ“ä½œç»“æœçš„å­—å…¸
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(CSV_PATH):
            return {"success": False, "message": "CSVæ–‡ä»¶ä¸å­˜åœ¨"}
        
        # å¤‡ä»½æ–‡ä»¶
        backup_path = f"{CSV_PATH}.bak"
        shutil.copy2(CSV_PATH, backup_path)
        
        # åˆ›å»ºç©ºçš„CSVæ–‡ä»¶
        with open(CSV_PATH, "w") as f:
            f.write("question,answer\n")
        
        # å®Œå…¨åˆ é™¤å‘é‡æ•°æ®åº“
        if os.path.exists(FAISS_PATH):
            shutil.rmtree(FAISS_PATH)
            # ç¡®ä¿ç›®å½•å­˜åœ¨ä½†ä¸ºç©º
            os.makedirs(FAISS_PATH, exist_ok=True)
        
        # ä½¿ç”¨é‡å»ºå‡½æ•°æ¥æ›´æ–°å‘é‡æ•°æ®åº“ï¼Œå¹¶ç¡®ä¿æ›´æ–°å…¨å±€å˜é‡
        global vectorstore, retriever
        vectorstore, retriever = rebuild_vectorstore()
        
        return {"success": True, "message": "CSVæ–‡ä»¶å·²é‡ç½®å¹¶æ¸…ç©ºäº†å‘é‡æ•°æ®åº“"}
    
    except Exception as e:
        print(f"âŒ åˆ é™¤CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return {"success": False, "message": f"åˆ é™¤CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

# === æ„å»ºRetriever ===

def initialize_vectorstore():
    """åˆå§‹åŒ–æˆ–é‡æ–°åŠ è½½å‘é‡æ•°æ®åº“"""
    global vectorstore, retriever
    
    # æ£€æŸ¥FAISSç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«å¿…è¦çš„æ–‡ä»¶
    if os.path.exists(FAISS_PATH) and os.path.exists(os.path.join(FAISS_PATH, "index.faiss")):
        print("ğŸ”„ åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“...")
        try:
            vectorstore = FAISS.load_local(
                str(FAISS_PATH),
                embedding_model,
                allow_dangerous_deserialization=True
            )
            print("âœ… æˆåŠŸåŠ è½½å‘é‡æ•°æ®åº“")
        except Exception as e:
            print(f"âŒ åŠ è½½å‘é‡æ•°æ®åº“å¤±è´¥: {str(e)}")
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œå°è¯•é‡å»º
            return rebuild_vectorstore()
    else:
        return rebuild_vectorstore()
        
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    return vectorstore, retriever

def rebuild_vectorstore():
    """é‡å»ºå‘é‡æ•°æ®åº“"""
    global vectorstore, retriever
    
    print("âš¡ æ„å»ºæ–°çš„å‘é‡æ•°æ®åº“...")
    if os.path.exists(CSV_PATH):
        faq_docs = load_faq_docs(str(CSV_PATH))
    else:
        # å¦‚æœCSVä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºæ–‡æ¡£
        faq_docs = [Document(page_content="è¿™æ˜¯ä¸€ä¸ªç©ºæ–‡æ¡£ï¼Œç”¨äºåˆå§‹åŒ–å‘é‡å­˜å‚¨")]
        
    # ç¡®ä¿ç›®å½•å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™
    try:
        os.makedirs(FAISS_PATH, exist_ok=True)
        # æµ‹è¯•ç›®å½•æ˜¯å¦å¯å†™
        test_file = os.path.join(FAISS_PATH, "test_write.tmp")
        with open(test_file, "w") as f:
            f.write("test")
        os.remove(test_file)
        
        # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
        vectorstore = FAISS.from_documents(faq_docs, embedding_model)

        print("âœ… æˆåŠŸåŠ è½½å‘é‡æ•°æ®åº“")
        # ä¿å­˜åˆ°ç£ç›˜
        vectorstore.save_local(str(FAISS_PATH))
        print(f"âœ… æˆåŠŸåˆ›å»ºå¹¶ä¿å­˜æ–°çš„å‘é‡æ•°æ®åº“ï¼ŒåŒ…å« {len(faq_docs)} ä¸ªæ–‡æ¡£")
        
        # æ›´æ–°æ£€ç´¢å™¨
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        return vectorstore, retriever
    except Exception as e:
        print(f"âŒ åˆ›å»ºå‘é‡æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
        raise

# åˆå§‹åŒ–å‘é‡æ•°æ®åº“
vectorstore, retriever = initialize_vectorstore()

